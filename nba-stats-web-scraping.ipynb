{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Introduction\nThe aim of this notebook is to scrape NBA player stats data to predict MVP. <br>\nAdapted from [Dataquest's](https://www.youtube.com/watch?v=JGQGd-oa0l4) YouTube video. <br>\n\nThis is a three part project:\n* Dataset: [1991-2021 NBA Stats](https://www.kaggle.com/datasets/vivovinco/19912021-nba-stats) <br>\n* First part: [NBA Stats: Web Scraping](https://www.kaggle.com/code/vivovinco/nba-stats-web-scraping) <br>\n* Second part: [NBA Stats: Data Cleaning](https://www.kaggle.com/code/vivovinco/nba-stats-data-cleaning) <br>\n* Third part: [NBA Stats: MVP Prediction](https://www.kaggle.com/code/vivovinco/nba-stats-mvp-prediction) <br>\n\n**If you're reading this, please upvote.**","metadata":{}},{"cell_type":"code","source":"!pip install selenium\n!pip install chromedriver-py==94.0.4606.41\n!pip install requests\n\n# libraries\nimport os\nimport pandas as pd\nimport shutil\nfrom selenium import webdriver\nfrom selenium.webdriver.common.keys import Keys\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nimport time\nfrom bs4 import BeautifulSoup as bs\nfrom chromedriver_py import binary_path\nimport requests\nimport warnings; warnings.filterwarnings(\"ignore\")\n\n# unhide all rows and columns\npd.set_option('display.max_rows', 50)\npd.set_option('display.max_columns', 50)\npd.set_option('display.width', 1000)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Scrape MVP List","metadata":{}},{"cell_type":"code","source":"years = list(range(1991,2022))\nurl_start = \"https://www.basketball-reference.com/awards/awards_{}.html\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfs = []\n\nfor year in years:\n    url = url_start.format(year)\n    data = requests.get(url)\n    \n    with open(\"./{}.html\".format(year), \"w+\") as f:\n        f.write(data.text)\n    \n    with open(\"./{}.html\".format(year)) as f:\n        page = f.read()\n        \n    soup = bs(page, \"html.parser\")\n    soup.find(\"tr\", class_ = \"over_header\").decompose()\n    mvp_table = soup.find_all(id = \"mvp\")\n    mvp = pd.read_html(str(mvp_table))[0]\n    mvp[\"Year\"] = year\n    \n    dfs.append(mvp)\n    mvps = pd.concat(dfs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mvps","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mvps.to_csv(\"mvps.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Scrape Player Stats","metadata":{}},{"cell_type":"code","source":"player_stats_url = \"https://www.basketball-reference.com/leagues/NBA_{}_per_game.html\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"driver = webdriver.Chrome(executable_path=\"/Users/.../chromedriver\")\n\nfor year in years:\n    url = player_stats_url.format(year)\n    \n    driver.get(url)\n    driver.execute_script(\"window.scrollTo(1,10000)\")\n    time.sleep(2)\n    \n    with open(\"player/{}.html\".format(year), \"w+\") as f:\n        f.write(driver.page_source)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfs = []\n\nfor year in years:\n    with open(\"player/{}.html\".format(year)) as f:\n        page = f.read()\n    \n    soup = BeautifulSoup(page, 'html.parser')\n    soup.find('tr', class_=\"thead\").decompose()\n    player_table = soup.find_all(id=\"per_game_stats\")[0]\n    player_df = pd.read_html(str(player_table))[0]\n    player_df[\"Year\"] = year\n    dfs.append(player_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"players = pd.concat(dfs)\nplayers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"players.to_csv(\"players.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"team_stats_url = \"https://www.basketball-reference.com/leagues/NBA_{}_standings.html\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for year in years:\n    url = team_stats_url.format(year)\n    \n    data = requests.get(url)\n    \n    with open(\"team/{}.html\".format(year), \"w+\") as f:\n        f.write(data.text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfs = []\nfor year in years:\n    with open(\"team/{}.html\".format(year)) as f:\n        page = f.read()\n    \n    soup = BeautifulSoup(page, 'html.parser')\n    soup.find('tr', class_=\"thead\").decompose()\n    e_table = soup.find_all(id=\"divs_standings_E\")[0]\n    e_df = pd.read_html(str(e_table))[0]\n    e_df[\"Year\"] = year\n    e_df[\"Team\"] = e_df[\"Eastern Conference\"]\n    del e_df[\"Eastern Conference\"]\n    dfs.append(e_df)\n    \n    w_table = soup.find_all(id=\"divs_standings_W\")[0]\n    w_df = pd.read_html(str(w_table))[0]\n    w_df[\"Year\"] = year\n    w_df[\"Team\"] = w_df[\"Western Conference\"]\n    del w_df[\"Western Conference\"]\n    dfs.append(w_df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"teams = pd.concat(dfs)\nteams","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"teams.to_csv(\"teams.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}